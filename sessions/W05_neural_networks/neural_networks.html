<!DOCTYPE html>
<html lang="en"><head>
<link href="../..//img/favicon.ico" rel="icon">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-1d5e050edb13250d4f64432100cad504.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.27">

  <meta name="author" content="Huanfa Chen">
  <title>Data Science for Spatial Systems – Neural Networks</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-708fdb05d86516b6f171cd9cf793ecac.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="Neural Networks – Data Science for Spatial Systems">
<meta property="og:description" content="Feed-Forward Networks and Deep Learning">
<meta property="og:image" content="https://huanfachen.github.io/DSSS_2025/sessions/W05_neural_networks/img/logo/full_sm.png">
<meta property="og:site_name" content="Foundations">
<meta property="og:locale" content="en_GB">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="title-slide" data-background-color="#4e3c56" data-background-image="../../img/web/title-slide.png" data-background-opacity="0.08" data-background-size="stretch" style="height:100%" class="center">

<br>
<br>

<h1 class="title">Neural Networks</h1>

  <h3 style="opacity:0.8;" class="subtitle">Feed-Forward Networks and Deep Learning</h3>

<p><span style="margin:0px; font-weight:700;" class="author">Huanfa Chen</span> - huanfa.chen@ucl.ac.uk </p>

<p style="opacity: 0.8">09/02/2026</p>


</section>
<section id="history" class="slide level2">
<h2>History</h2>
<div style="text-align:center;">
<img src="images/history_of_AI.png" alt="History of neural net" style="max-width:80%;">
<div style="font-size:0.8em; color: #555; margin-top:4px;">
<pre><code>Image Credit: medium.com</code></pre>
</div>
</div>
</section>
<section id="history-1" class="slide level2">
<h2>History</h2>
<div style="text-align:center;">
<p><img src="images/history_of_AI.png" alt="History of neural net" style="max-width:40%;"></p>
</div>
<ul>
<li>Nearly everything we talk about today existed in 1990</li>
<li>What changed since then?
<ul>
<li>More data</li>
<li>Faster computers (GPUs)</li>
<li>Some improvements: Relu, dropout, adam, batch-normalization, residual networks</li>
</ul></li>
</ul>
</section>
<section id="linear-regression-as-neural-net" class="slide level2">
<h2>Linear Regression as Neural Net</h2>
<p><span class="math inline">\(y = \sum_i W_i x_i + b = Wx\)</span></p>
<div style="text-align:center;">
<p><img src="images/log_reg_nn.png" alt="Logistic regression as neural net" style="max-width:40%;"></p>
</div>
</section>
<section id="logistic-regression-as-neural-net" class="slide level2">
<h2>Logistic Regression as Neural Net</h2>
<p><span class="math inline">\(y = \sigma(Wx)\)</span></p>
<p><span class="math inline">\(\sigma(z) = \frac{1}{1 + e^{-z}}\)</span></p>
<div style="text-align:center;">
<p><img src="images/log_reg_nn.png" alt="Logistic regression as neural net" style="max-width:40%;"></p>
</div>
</section>
<section id="basic-architecture-of-neural-networks" class="slide level2">
<h2>Basic Architecture of Neural Networks</h2>
<p><span class="math inline">\(h(x) = f(W_1x+b_1)\)</span>; f: hidden layer activation function</p>
<p><span class="math inline">\(o(x) = g(W_2h(x) + b_2)\)</span> g: output layer activation function</p>
<div style="text-align:center;">
<p><img src="images/nn_basic_arch.png" alt="Basic neural network architecture" style="max-width:50%;"></p>
</div>
</section>
<section id="output-layer-activation-function-g" class="slide level2">
<h2>Output layer activation function <span class="math inline">\(g\)</span></h2>
<div style="text-align:center;">
<p><img src="images/nn_basic_arch.png" alt="Basic neural network architecture" style="max-width:50%;"></p>
</div>
<ul>
<li>For regression: <span class="math inline">\(g\)</span> is identity function <span class="math inline">\(g(z) = z\)</span></li>
<li>For binary classification: <span class="math inline">\(g\)</span> is sigmoid function <span class="math inline">\(g(z) = \sigma(z)\)</span> (to output a probability [0,1])</li>
<li>For multi-class classification: <span class="math inline">\(g\)</span> is softmax function <span class="math inline">\(g(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}\)</span> (to output a probability distribution over classes)</li>
</ul>
</section>
<section id="nonlinear-activation-functions-f" class="slide level2">
<h2>Nonlinear Activation Functions <span class="math inline">\(f\)</span></h2>
<div style="text-align:center;">
<p><img src="images/nonlin_fn.png" alt="Nonlinear activation functions" style="max-width:65%;"></p>
</div>
<ul>
<li>The primary job of <em>f</em> is to break the linearity of the model</li>
<li>Standard choices: tanh (pronounced like “than”) or relu (rectified linear unit)</li>
<li>Tanh squashes between -1 and 1; saturates towards infinities</li>
<li>ReLU is constant zero for negative numbers, then identity</li>
</ul>
</section>
<section id="more-layers" class="slide level2">
<h2>More Layers</h2>
<div style="text-align:center;">
<p><img src="images/nn_manylayers.png" alt="Neural network with many layers" style="max-width:60%;"></p>
</div>
<ul>
<li>Hidden layers usually all have the same non-linear function</li>
<li>Other names: Multilayer perceptron, feed-forward neural network</li>
<li>Many layers → “deep learning”</li>
</ul>
</section>
<section id="supervised-neural-networks" class="slide level2">
<h2>Supervised Neural Networks</h2>
<ul>
<li>Non-linear models for classification and regression</li>
<li>Work well for very large datasets</li>
<li>Notoriously slow to train; need for GPUs</li>
<li>Use dot products <span class="math inline">\(Wx\)</span>; require preprocessing similar to SVM or PCA, unlike trees</li>
<li>Many variants: Convolutional nets, GRUs, LSTMs, recursive networks, VAEs, GANs, deep RL</li>
</ul>
</section>
<section id="training-objective" class="slide level2">
<h2>Training Objective</h2>
<p><span class="math inline">\(h(x) = f(W_1x+b_1)\)</span></p>
<p><span class="math inline">\(o(x) = g(W_2h(x)+b_2) = g(W_2f(W_1x + b_1) + b_2)\)</span></p>
<p><span class="math inline">\(\min_{W_1,W_2,b_1,b_2} \sum\limits_{i=1}^N l(y_i,o(x_i))\)</span></p>
<p><span class="math inline">\(= \min_{W_1,W_2,b_1,b_2} \sum\limits_{i=1}^N l(y_i,g(W_2f(W_1x+b_1)+b_2))\)</span></p>
<ul>
<li><span class="math inline">\(l\)</span> = Squared loss for regression; Cross-entropy loss for classification</li>
</ul>
</section>
<section id="backpropagation" class="slide level2">
<h2>Backpropagation</h2>
<ul>
<li>Need <span class="math inline">\(\frac{\partial l(y, o)}{\partial W_i}\)</span> and <span class="math inline">\(\frac{\partial l(y, o)}{\partial b_i}\)</span></li>
</ul>
<p><span class="math inline">\(\text{net}(x) := W_1x + b_1\)</span></p>
<div style="text-align:center;">
<p><img src="images/backprop_eqn.png" alt="Backpropagation equations" style="max-width:70%;"></p>
</div>
</section>
<section id="gradient-computation" class="slide level2">
<h2>Gradient Computation</h2>
<ul>
<li>Backpropagation is clever application of chain rule for derivatives</li>
<li>Single backward pass from output to input computes derivatives</li>
<li>Not an optimisation algorithm, just a way to compute gradients</li>
</ul>
</section>
<section id="relu-differentiability" class="slide level2">
<h2>ReLU Differentiability</h2>
<div style="text-align:center;">
<p><img src="images/relu_differentiability.png" alt="ReLU differentiability" style="max-width:75%;"></p>
</div>
<ul>
<li>ReLU not differentiable at zero. At x&gt;0, gradient is 1; at x&lt;0, gradient is 0</li>
<li><em>For a function to be differentiable, the slope must be the same whether approaching from the left or right</em></li>
<li>Use subgradient descent; any gradient <em>below</em> the function works</li>
<li>In practice, most FL framewors simply hardcode the gradient at zero to be 0 or 0.5</li>
</ul>
</section>
<section id="optimising-w-b" class="slide level2">
<h2>Optimising W, b</h2>
<p>Batch <span class="math inline">\(W_i \leftarrow W_i - \eta\sum\limits_{j=1}^N \frac{\partial l(x_j,y_j)}{\partial W_i}\)</span></p>
<p>Online/Stochastic <span class="math inline">\(W_i \leftarrow W_i - \eta\frac{\partial l(x_j,y_j)}{\partial W_i}\)</span></p>
<p>Minibatch <span class="math inline">\(W_i \leftarrow W_i - \eta\sum\limits_{j=k}^{k+m} \frac{\partial l(x_j,y_j)}{\partial W_i}\)</span></p>
</section>
<section id="learning-heuristics" class="slide level2">
<h2>Learning Heuristics</h2>
<ul>
<li>Constant <span class="math inline">\(\eta\)</span> not good</li>
<li>Can decrease <span class="math inline">\(\eta\)</span> over time</li>
<li>Better: adaptive <span class="math inline">\(\eta\)</span> for each entry of <span class="math inline">\(W_i\)</span></li>
<li>State-of-the-art: adam (with magic numbers)</li>
</ul>
</section>
<section id="picking-optimization-algorithms" class="slide level2">
<h2>Picking Optimization Algorithms</h2>
<ul>
<li>Small dataset: off the shelf like l-bfgs</li>
<li>Big dataset: adam / rmsprop</li>
<li>Have time &amp; nerve: tune the schedule</li>
</ul>
</section>
<section id="neural-nets-with-sklearn" class="slide level2">
<h2>Neural Nets with sklearn</h2>
<div style="text-align:center;">
<p><img src="images/nn_sklearn.png" alt="Neural nets with sklearn" style="max-width:45%;"></p>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>mlp <span class="op">=</span> MLPClassifier(solver<span class="op">=</span><span class="st">'lbfgs'</span>, random_state<span class="op">=</span><span class="dv">0</span>).fit(X_train, y_train)</span>
<span id="cb2-2"><a></a><span class="bu">print</span>(mlp.score(X_train, y_train))</span>
<span id="cb2-3"><a></a><span class="bu">print</span>(mlp.score(X_test, y_test))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li>Don’t use sklearn for real projects but toy problems in neural nets</li>
<li>Why? sklearn’s MLP is not optimised for large datasets; no GPU support; no support for conv nets, etc.</li>
</ul>
</section>
<section id="complexity-control" class="slide level2">
<h2>Complexity Control</h2>
<ul>
<li>Number of parameters: hidden layers, hidden units</li>
<li>Regularisation</li>
<li>Early Stopping</li>
<li>Dropout</li>
</ul>
</section>
<section id="random-state" class="slide level2">
<h2>Random State</h2>
<div style="text-align:center;">
<p><img src="images/random_state.png" alt="Effect of random state" style="max-width:75%;"></p>
</div>
<ul>
<li>Network is way over capacity and can overfit in many ways</li>
<li>Regularisation might make it less dependent on initialization</li>
</ul>
</section>
<section>
<section id="regularisation" class="title-slide slide level1 center">
<h1>Regularisation</h1>
<ul>
<li>Without regularisation, can easily overfit with large networks. Loss function: <span class="math inline">\(L = \sum\limits_{i=1}^N l(y_i, o(x_i))\)</span></li>
<li><strong>L2 regularisation</strong>: add <span class="math inline">\(\lambda \sum\limits_i W_i^2\)</span> to loss function; penalise large weights</li>
<li><strong>L1 regularisation</strong>: add <span class="math inline">\(\lambda \sum\limits_i |W_i|\)</span> to loss function</li>
<li><strong>Dropout</strong>: randomly set some activations to zero during training; prevents co-adaptation of neurons</li>
</ul>
</section>
<section id="hidden-layer-size" class="slide level2">
<h2>Hidden Layer Size</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a>mlp <span class="op">=</span> MLPClassifier(solver<span class="op">=</span><span class="st">'lbfgs'</span>, hidden_layer_sizes<span class="op">=</span>(<span class="dv">5</span>,), random_state<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb3-2"><a></a>mlp.fit(X_train, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div style="text-align:center;">
<p><img src="images/hidden_layer_size.png" alt="Hidden layer size effect" style="max-width:50%;"></p>
</div>
<ul>
<li>Single hidden layer with 5 units</li>
<li>Each unit corresponds to different part of decision boundary</li>
</ul>
</section>
<section id="multiple-hidden-layers" class="slide level2">
<h2>Multiple Hidden Layers</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>mlp <span class="op">=</span> MLPClassifier(solver<span class="op">=</span><span class="st">'lbfgs'</span>, hidden_layer_sizes<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>), random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-2"><a></a>mlp.fit(X_train, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div style="text-align:center;">
<p><img src="images/hidden_layer_size_2.png" alt="Multiple hidden layers" style="max-width:48%;"></p>
</div>
<ul>
<li>3 hidden layers each of size 10</li>
<li>Main way to control complexity</li>
</ul>
</section>
<section id="activation-functions" class="slide level2">
<h2>Activation Functions</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a>mlp <span class="op">=</span> MLPClassifier(solver<span class="op">=</span><span class="st">'lbfgs'</span>, hidden_layer_sizes<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>),</span>
<span id="cb5-2"><a></a>                    activation<span class="op">=</span><span class="st">'tanh'</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-3"><a></a>mlp.fit(X_train, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div style="text-align:center;">
<p><img src="images/activation_functions_plot.png" alt="Activation functions" style="max-width:45%;"></p>
</div>
<ul>
<li>Using tanh gives smoother boundaries</li>
<li>ReLU doesn’t work as well with l-bfgs on small networks</li>
<li>For large networks, relu is preferred</li>
</ul>
</section>
<section id="regression" class="slide level2">
<h2>Regression</h2>
<div style="text-align:center;">
<p><img src="images/regression_plot.png" alt="Neural network regression" style="max-width:55%;"></p>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPRegressor</span>
<span id="cb6-2"><a></a>mlp_relu <span class="op">=</span> MLPRegressor(solver<span class="op">=</span>\<span class="st">"lbfgs</span><span class="ch">\"</span><span class="st">).fit(X, y)</span></span>
<span id="cb6-3"><a></a><span class="er">mlp_tanh = MLPRegressor</span>(solver<span class="op">=</span>\<span class="st">"lbfgs</span><span class="ch">\"</span><span class="st">, activation='tanh').fit(X, y)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="grid-searching-neural-nets" class="slide level2">
<h2>Grid-Searching Neural Nets</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb7-2"><a></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb7-3"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb7-4"><a></a>    data.data, data.target, stratify<span class="op">=</span>data.target, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-5"><a></a></span>
<span id="cb7-6"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb7-7"><a></a>pipe <span class="op">=</span> make_pipeline(StandardScaler(), MLPClassifier(solver<span class="op">=</span>\<span class="st">"lbfgs</span><span class="ch">\"</span><span class="st">, random_state=1))</span></span>
<span id="cb7-8"><a></a><span class="er">param_grid = {'mlpclassifier__alpha': np.logspace(-3, 3, 7)}</span></span>
<span id="cb7-9"><a></a>grid <span class="op">=</span> GridSearchCV(pipe, param_grid)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div style="text-align:center;">
<p><img src="images/gridsearch_plot.png" alt="Grid search results" style="max-width:45%;"></p>
</div>
</section>
<section id="searching-hidden-layer-sizes" class="slide level2">
<h2>Searching Hidden Layer Sizes</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb8-2"><a></a>pipe <span class="op">=</span> make_pipeline(StandardScaler(), MLPClassifier(solver<span class="op">=</span>\<span class="st">"lbfgs</span><span class="ch">\"</span><span class="st">, random_state=1))</span></span>
<span id="cb8-3"><a></a><span class="er">param_grid = {'mlpclassifier__hidden_layer_sizes':</span></span>
<span id="cb8-4"><a></a>              [(<span class="dv">10</span>,), (<span class="dv">50</span>,), (<span class="dv">100</span>,), (<span class="dv">500</span>,), (<span class="dv">10</span>, <span class="dv">10</span>), (<span class="dv">50</span>, <span class="dv">50</span>), (<span class="dv">100</span>, <span class="dv">100</span>), (<span class="dv">500</span>, <span class="dv">500</span>)]}</span>
<span id="cb8-5"><a></a>grid <span class="op">=</span> GridSearchCV(pipe, param_grid)</span>
<span id="cb8-6"><a></a>grid.fit(X_train, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div style="text-align:center;">
<p><img src="images/search_hidden_layers_plot.png" alt="Search hidden layer sizes" style="max-width:40%;"></p>
</div>
<!-- ## Write Your Own Neural Networks

```python
class NeuralNetwork(object):
    def __init__(self):
        # initialize coefficients and biases
        pass
    def forward(self, x):
        activation = x
        for coef, bias in zip(self.coef_, self.bias_):
            activation = self.nonlinearity(np.dot(activation, coef) + bias)
        return activation
    def backward(self, x):
        # compute gradient of stuff in forward pass
        pass
```

## Autodiff

```python
class array(object) :
    \"\"\"Simple Array object that support autodiff.\"\"\"
    def __init__(self, value, name=None):
        self.value = value
        if name:
            self.grad = lambda g : {name : g}
    def __add__(self, other):
        assert isinstance(other, int)
        ret = array(self.value + other)
        ret.grad = lambda g : self.grad(g)
        return ret
    def __mul__(self, other):
        assert isinstance(other, array)
        ret = array(self.value * other.value)
        def grad(g):
            x = self.grad(g * other.value)
            x.update(other.grad(g * self.value))
            return x
        ret.grad = grad
        return ret
```

## Autodiff Example

```python
a = array(np.array([1, 2]), 'a')
b = array(np.array([3, 4]), 'b')
c = b * a
d = c + 1
print(d.value)
print(d.grad(1))
```

```
[4 9]
{'b': array([1, 2]), 'a': array([3, 4])}
```

- Automatic differentiation avoids writing gradients manually
- Keep track of computation while executing forward pass
- Hard-code derivative for each operation (no symbolic differentiation)
- Build computation graph automatically -->
</section>
<section id="gpu-support" class="slide level2">
<h2>GPU Support</h2>
<div style="text-align:center;">
<p><img src="images/gpu_support.png" alt="GPU performance" style="max-width:55%;"></p>
</div>
<ul>
<li>Important limitation: GPUs have much less memory than RAM</li>
<li>Memory copies between RAM and GPU are expensive</li>
</ul>
</section>
<section id="cpu-vs.-gpu" class="slide level2">
<h2>CPU VS. GPU</h2>
<table class="caption-top">
<colgroup>
<col style="width: 25%">
<col style="width: 37%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>CPU</th>
<th>GPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Architecture</td>
<td>Few cores optimised for sequential tasks</td>
<td>Thousands of cores for parallel processing</td>
</tr>
<tr class="even">
<td>Performance</td>
<td>Better for single-threaded tasks</td>
<td>Superior for parallel tasks like matrix operations</td>
</tr>
<tr class="odd">
<td>Memory</td>
<td>Larger cache size, less memory bandwidth</td>
<td>Higher memory bandwidth, less cache size</td>
</tr>
<tr class="even">
<td>Power Consumption</td>
<td>Generally lower power consumption</td>
<td>Higher power consumption due to many cores</td>
</tr>
<tr class="odd">
<td>Use Cases</td>
<td>General-purpose computing, complex logic</td>
<td>Graphics rendering, deep learning, scientific simulations</td>
</tr>
<tr class="even">
<td>Cost</td>
<td>Less expensive</td>
<td>Expensive</td>
</tr>
<tr class="odd">
<td>Programming Complexity</td>
<td>Easier to program for general tasks</td>
<td>Requires knowledge of parallel programming (e.g., CUDA)</td>
</tr>
</tbody>
</table>
</section>
<section id="how-much-gpu-power-do-you-need" class="slide level2">
<h2>How much GPU power do you need?</h2>
<table class="caption-top">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Task Type</th>
<th>Typical GPU</th>
<th>Total GPU Hours</th>
<th>Estimated Cost (Cloud)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Small Project</strong> (MNIST, basic CNN)</td>
<td>1x RTX 3060 / 4060</td>
<td>&lt; 1 hour</td>
<td>&lt; $1</td>
</tr>
<tr class="even">
<td><strong>Fine-tuning 7B LLM</strong> (e.g., Llama 3 8B)</td>
<td>1x A100 (80GB)</td>
<td>5–20 hours</td>
<td>$10 – $40</td>
</tr>
<tr class="odd">
<td><strong>Training Mid-size Model</strong> (e.g., Stable Diffusion)</td>
<td>8x A100 Cluster</td>
<td>500–2,000 hours</td>
<td>$1,000 – $5,000</td>
</tr>
<tr class="even">
<td><strong>Pre-training Large LLM</strong> (GPT-3/4 scale)</td>
<td>10,000+ H100s</td>
<td>Millions of hours</td>
<td>$50M – $100M+</td>
</tr>
</tbody>
</table>
</section>
<section id="computational-graph" class="slide level2">
<h2>Computational Graph</h2>
<div style="text-align:center;">
<p><img src="images/computation_graph.png" alt="Computation graph" style="max-width:60%;"></p>
</div>
<ul>
<li>A ‘blue-print’, or a directed acyclic graph representing computations in a neural network</li>
<li>Nodes represent variabels or operations (e.g., matrix multiplication, activation functions), edges represent flow of data (tensors) between operations</li>
<li>Given limited GPU memory, important to know what to cache/discard</li>
<li>Helps with visual debugging and understanding network structure</li>
</ul>
</section>
<section id="deep-learning-framework-requirements" class="slide level2">
<h2>Deep Learning Framework Requirements</h2>
<ul>
<li>Autodiff</li>
<li>GPU support</li>
<li>Optimisation and inspection of computation graph</li>
<li>On-the-fly generation of computation graph (optional)</li>
<li>Distribution over multiple GPUs and/or cluster (optional)</li>
</ul>
<p>Current choices: PyTorch / Torch, TensorFlow</p>
</section>
<section id="deep-learning-libraries" class="slide level2">
<h2>Deep Learning Libraries</h2>
<ul>
<li>PyTorch (torch) (<em>default for AI research &amp; development</em>)</li>
<li>Keras (TensorFlow, CNTK, Theano) (<em>enterprise production</em>)</li>
<li>Chainer (chainer)</li>
<li>MXNet (MXNet)</li>
</ul>
</section>
<section id="quick-look-at-tensorflow" class="slide level2">
<h2>Quick Look at TensorFlow</h2>
<ul>
<li>"Down to the metal" - don’t use for everyday tasks</li>
<li>Three steps for learning:
<ol type="1">
<li>Build computation graph (using array operations and functions)</li>
<li>Create Optimizer (gradient descent, adam, etc.) attached to graph</li>
<li>Run actual computation</li>
</ol></li>
<li>Eager mode (default in TensorFlow 2.0): write imperative code directly</li>
</ul>
<div style="text-align:center;">
<p><img src="images/tensor_flow_basics.png" alt="TensorFlow basics" style="max-width:75%;"></p>
</div>
</section>
<section id="pytorch-example" class="slide level2">
<h2>PyTorch Example</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>dtype <span class="op">=</span> torch.<span class="bu">float</span></span>
<span id="cb9-2"><a></a>device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>)</span>
<span id="cb9-3"><a></a></span>
<span id="cb9-4"><a></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb9-5"><a></a>x <span class="op">=</span> torch.randn(N, <span class="dv">1</span>, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb9-6"><a></a>y <span class="op">=</span> torch.randn(N, <span class="dv">1</span>, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb9-7"><a></a>w <span class="op">=</span> torch.randn(D_in, H, device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb9-8"><a></a></span>
<span id="cb9-9"><a></a>learning_rate <span class="op">=</span> <span class="fl">1e-6</span></span>
<span id="cb9-10"><a></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">500</span>):</span>
<span id="cb9-11"><a></a>    y_pred <span class="op">=</span> x.mm(w1)</span>
<span id="cb9-12"><a></a>    loss <span class="op">=</span> (y_pred <span class="op">-</span> y).<span class="bu">pow</span>(<span class="dv">2</span>).<span class="bu">sum</span>().item()</span>
<span id="cb9-13"><a></a>    loss.backward()</span>
<span id="cb9-14"><a></a>    w1 <span class="op">-=</span> learning_rate <span class="op">*</span> w1.grad</span>
<span id="cb9-15"><a></a>    w1.grad.zero_()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="best-practices" class="slide level2">
<h2>Best Practices</h2>
<ul>
<li>Don’t go down to the metal (i.e.&nbsp;write low-level code) unless you have to!</li>
<li>Don’t write TensorFlow, write Keras!</li>
<li>Don’t write PyTorch, write pytorch.nn or FastAI (or Skorch or ignite)</li>
</ul>
</section></section>
<section>
<section id="convolutional-neural-networks" class="title-slide slide level1 center">
<h1>Convolutional Neural Networks</h1>

</section>
<section id="idea-1-behind-cnns" class="slide level2">
<h2>Idea #1 Behind CNNs</h2>
<ul>
<li><strong>Translation invariance</strong>: CNN can recognise an object regardless of where it is in the frame.</li>
<li>… because the same filters scan every part of the image (weight sharing)</li>
</ul>
<div style="text-align:center;">
<p><img src="images/translation_invariance_dog.png" alt="Translation invariance in CNNs" style="max-width:80%;"></p>
</div>
</section>
<section id="idea-2-behind-cnns" class="slide level2">
<h2>Idea #2 Behind CNNs</h2>
<ul>
<li><strong>Weight sharing</strong>: the principle that the same set of weights (a filter, or kernel) is used to scan every part of an image</li>
<li>So, this filter will detect a specific feature (e.g.&nbsp;edge, curve), regardless of its position</li>
<li>Each filter corresponds to a specific feature or pattern, rather than location-specific information</li>
</ul>
</section>
<section id="why-weight-sharing" class="slide level2">
<h2>Why Weight Sharing?</h2>
<ul>
<li>Reduces number of parameters; less prone to overfitting</li>
<li>Comparison: for a 100x100 image with 3 channels (RGB), a fully connected layer in NN with 100 hidden units would have 3 million parameters (100<em>100</em>3*100);</li>
<li>a convolutional layer with 10 filters of size 5x5 would have only 750 parameters (5<em>5</em>10)</li>
</ul>
</section>
<section id="definition-of-convolution" class="slide level2">
<h2>Definition of Convolution</h2>
<p><span class="math display">\[(f*g)[n] = \sum\limits_{m=-\infty}^\infty f[m]g[n-m]\]</span></p>
<p><span class="math display">\[= \sum\limits_{m=-\infty}^\infty f[n-m]g[m]\]</span></p>
<div style="text-align:center;">
<p><img src="images/convolution.png" alt="Convolution definition" style="max-width:80%;"></p>
</div>
</section>
<section id="d-example-gaussian-smoothing" class="slide level2">
<h2>1D Example: Gaussian Smoothing</h2>
<div style="text-align:center;">
<p><img src="images/Gaussian_Smoothing.png" alt="Gaussian smoothing" style="max-width:80%;"></p>
</div>
</section>
<section id="convolutions-in-2d" class="slide level2">
<h2>Convolutions in 2D</h2>
<div style="text-align:center;">
<p><img src="images/2dconv_illustration.png" alt="2D convolution illustration" style="max-width:70%;"></p>
</div>
<p><a href="https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">source: Arden Dertat</a></p>
</section>
<section id="d-convolution-animation" class="slide level2">
<h2>2D Convolution Animation</h2>
<div style="text-align:center;">
<p><img src="images/2dconv_animation.gif" alt="2D convolution animation" style="max-width:90%;"></p>
</div>
<p><a href="https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">source: Arden Dertat</a></p>
</section>
<section id="d-smoothing" class="slide level2">
<h2>2D Smoothing</h2>
<div style="text-align:center;">
<p><img src="images/2dsmoothing.png" alt="2D smoothing" style="max-width:80%;"></p>
</div>
</section>
<section id="d-gradients" class="slide level2">
<h2>2D Gradients</h2>
<div style="text-align:center;">
<p><img src="images/2dgradient.png" alt="2D gradients" style="max-width:80%;"></p>
</div>
</section>
<section id="max-pooling" class="slide level2">
<h2>Max Pooling</h2>
<div style="text-align:center;">
<p><img src="images/maxpool.png" alt="Max pooling" style="max-width:100%;"></p>
</div>
<ul>
<li>Need to remember position of maximum for back-propagation</li>
<li>Again not differentiable → subgradient descent</li>
</ul>
</section>
<section id="convolutional-neural-networks-1" class="slide level2">
<h2>Convolutional Neural Networks</h2>
<div style="text-align:center;">
<p><img src="images/CNET1.png" alt="Convolutional neural network" style="max-width:100%;"></p>
</div>
<ul>
<li>Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner: Gradient-based learning applied to document recognition</li>
</ul>
</section>
<section id="other-architectures" class="slide level2">
<h2>Other Architectures</h2>
<div style="text-align:center;">
<p><img src="images/other_architectures.png" alt="Other architectures" style="max-width:80%;"></p>
</div>
</section>
<section id="conv-nets-with-keras" class="slide level2">
<h2>Conv-nets with Keras</h2>
</section>
<section id="preparing-data" class="slide level2">
<h2>Preparing Data</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>batch_size <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb10-2"><a></a>num_classes <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb10-3"><a></a>epochs <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb10-4"><a></a></span>
<span id="cb10-5"><a></a>img_rows, img_cols <span class="op">=</span> <span class="dv">28</span>, <span class="dv">28</span></span>
<span id="cb10-6"><a></a></span>
<span id="cb10-7"><a></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> mnist.load_data()</span>
<span id="cb10-8"><a></a></span>
<span id="cb10-9"><a></a>X_train_images <span class="op">=</span> x_train.reshape(x_train.shape[<span class="dv">0</span>], img_rows, img_cols, <span class="dv">1</span>)</span>
<span id="cb10-10"><a></a>X_test_images <span class="op">=</span> x_test.reshape(x_test.shape[<span class="dv">0</span>], img_rows, img_cols, <span class="dv">1</span>)</span>
<span id="cb10-11"><a></a>input_shape <span class="op">=</span> (img_rows, img_cols, <span class="dv">1</span>)</span>
<span id="cb10-12"><a></a></span>
<span id="cb10-13"><a></a>y_train <span class="op">=</span> keras.utils.to_categorical(y_train, num_classes)</span>
<span id="cb10-14"><a></a>y_test <span class="op">=</span> keras.utils.to_categorical(y_test, num_classes)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="create-tiny-network" class="slide level2">
<h2>Create Tiny Network</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a><span class="im">from</span> keras.layers <span class="im">import</span> Conv2D, MaxPooling2D, Flatten</span>
<span id="cb11-2"><a></a></span>
<span id="cb11-3"><a></a>num_classes <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb11-4"><a></a>cnn <span class="op">=</span> Sequential()</span>
<span id="cb11-5"><a></a>cnn.add(Conv2D(<span class="dv">32</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb11-6"><a></a>                 activation<span class="op">=</span><span class="st">'relu'</span>,</span>
<span id="cb11-7"><a></a>                 input_shape<span class="op">=</span>input_shape))</span>
<span id="cb11-8"><a></a>cnn.add(MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb11-9"><a></a>cnn.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb11-10"><a></a>cnn.add(MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb11-11"><a></a>cnn.add(Flatten())</span>
<span id="cb11-12"><a></a>cnn.add(Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb11-13"><a></a>cnn.add(Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="number-of-parameters" class="slide level2">
<h2>Number of Parameters</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Convolutional Network for MNIST</p>
<div style="text-align:center;">
<p><img src="images/cnn_params_mnist.png" alt="CNN parameters" style="max-width:100%;"></p>
</div>
</div><div class="column" style="width:50%;">
<p>Dense Network for MNIST</p>
<div style="text-align:center;">
<p><img src="images/dense_params_mnist.png" alt="Dense parameters" style="max-width:100%;"></p>
</div>
</div></div>
</section>
<section id="train-and-evaluate" class="slide level2">
<h2>Train and Evaluate</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a>cnn.<span class="bu">compile</span>(\<span class="st">"adam</span><span class="ch">\"</span><span class="st">, </span><span class="ch">\"</span><span class="st">categorical_crossentropy</span><span class="ch">\"</span><span class="st">, metrics=['accuracy'])</span></span>
<span id="cb12-2"><a></a><span class="er">history_cnn = cnn.fit</span>(X_train_images, y_train,</span>
<span id="cb12-3"><a></a>                      batch_size<span class="op">=</span><span class="dv">128</span>, epochs<span class="op">=</span><span class="dv">20</span>, verbose<span class="op">=</span><span class="dv">1</span>, validation_split<span class="op">=</span><span class="fl">.1</span>)</span>
<span id="cb12-4"><a></a>cnn.evaluate(X_test_images, y_test)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<pre><code> 9952/10000 [============================&gt;.] - ETA: 0s
 [0.089020583277629253, 0.98429999999999995]</code></pre>
<div style="text-align:center;">
<p><img src="images/train_evaluate.png" alt="Train and evaluate" style="max-width:50%;"></p>
</div>
</section>
<section id="visualise-filters" class="slide level2">
<h2>Visualise Filters</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>weights, biases <span class="op">=</span> cnn_small.layers[<span class="dv">0</span>].get_weights()</span>
<span id="cb14-2"><a></a>weights2, biases2 <span class="op">=</span> cnn_small.layers[<span class="dv">2</span>].get_weights()</span>
<span id="cb14-3"><a></a><span class="bu">print</span>(weights.shape)</span>
<span id="cb14-4"><a></a><span class="bu">print</span>(weights2.shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<pre><code>(3,3,1,8)
(3,3,8,8)</code></pre>
<div style="text-align:center;">
<p><img src="images/visualize_filters.png" alt="Visualize filters" style="max-width:40%;"></p>
</div>
</section>
<section id="learned-features" class="slide level2">
<h2>Learned Features</h2>
<div style="text-align:center;">
<p><img src="images/digits.png" alt="Learned features" style="max-width:80%;"></p>
</div>
</section>
<section id="mnist-and-permuted-mnist" class="slide level2">
<h2>MNIST and Permuted MNIST</h2>
<div style="text-align:center;">
<p><img src="images/mnist_org.png" alt="MNIST original" style="max-width:90%;"></p>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a>rng <span class="op">=</span> np.random.RandomState(<span class="dv">42</span>)</span>
<span id="cb16-2"><a></a>perm <span class="op">=</span> rng.permutation(<span class="dv">784</span>)</span>
<span id="cb16-3"><a></a>X_train_perm <span class="op">=</span> X_train.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)[:, perm].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb16-4"><a></a>X_test_perm <span class="op">=</span> X_test.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)[:, perm].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div style="text-align:center;">
<p><img src="images/mnist_permuted.png" alt="MNIST permuted" style="max-width:90%;"></p>
</div>
</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<ul>
<li>We’ve covered the architecture and training of neural networks</li>
<li>We also covered the idea and implementation of convolutional neural networks</li>
</ul>
</section>
<section id="questions" class="slide level2">
<h2>Questions?</h2>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../img/logo/full.svg" class="slide-logo"></p>
<div class="footer footer-default">
<p>© CASA &nbsp; | &nbsp; <a href="https://www.ucl.ac.uk/bartlett/casa">ucl.ac.uk/bartlett/casa</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/huanfachen\.github\.io\/DSSS_2025\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>